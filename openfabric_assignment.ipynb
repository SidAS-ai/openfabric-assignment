{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install openai openfabric_pysdk torch transformers accelerate sentence_transformers gradio huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLz3r2fjoIlZ",
        "outputId": "35bbac80-51bd-4337-bb39-090c86d1cfc7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.72.0)\n",
            "Requirement already satisfied: openfabric_pysdk in /usr/local/lib/python3.11/dist-packages (0.2.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.25.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: Flask<3.0.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (2.3.3)\n",
            "Requirement already satisfied: Flask-Cors<4.0.0,>=3.0.10 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (3.0.10)\n",
            "Requirement already satisfied: Flask-RESTful<0.4.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (0.3.10)\n",
            "Requirement already satisfied: Flask-SocketIO<6.0.0,>=5.3.6 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (5.5.1)\n",
            "Requirement already satisfied: Werkzeug>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (3.1.3)\n",
            "Requirement already satisfied: flask-apispec<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (0.11.4)\n",
            "Requirement already satisfied: gevent<23.0.0,>=22.10.2 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (22.10.2)\n",
            "Requirement already satisfied: gevent-websocket<0.11.0,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (0.10.1)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (1.5.1)\n",
            "Requirement already satisfied: marshmallow-jsonapi<0.25.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (0.24.0)\n",
            "Requirement already satisfied: pickleDB<0.10.0,>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (0.9.2)\n",
            "Requirement already satisfied: pyzmq<26.0.0,>=25.1.1 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (25.1.2)\n",
            "Requirement already satisfied: runstats<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (2.0.0)\n",
            "Requirement already satisfied: socketio-client<0.8.0,>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from openfabric_pysdk) (0.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.1.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.1)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.0.0,>=2.0.1->openfabric_pysdk) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.0.0,>=2.0.1->openfabric_pysdk) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.0.0,>=2.0.1->openfabric_pysdk) (1.9.0)\n",
            "Requirement already satisfied: marshmallow>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from flask-apispec<0.12.0,>=0.11.0->openfabric_pysdk) (4.0.0)\n",
            "Requirement already satisfied: webargs>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from flask-apispec<0.12.0,>=0.11.0->openfabric_pysdk) (8.6.0)\n",
            "Requirement already satisfied: apispec>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from flask-apispec<0.12.0,>=0.11.0->openfabric_pysdk) (6.8.1)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.11/dist-packages (from Flask-Cors<4.0.0,>=3.0.10->openfabric_pysdk) (1.17.0)\n",
            "Requirement already satisfied: aniso8601>=0.82 in /usr/local/lib/python3.11/dist-packages (from Flask-RESTful<0.4.0,>=0.3.9->openfabric_pysdk) (10.0.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from Flask-RESTful<0.4.0,>=0.3.9->openfabric_pysdk) (2025.2)\n",
            "Requirement already satisfied: python-socketio>=5.12.0 in /usr/local/lib/python3.11/dist-packages (from Flask-SocketIO<6.0.0,>=5.3.6->openfabric_pysdk) (5.13.0)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.11/dist-packages (from gevent<23.0.0,>=22.10.2->openfabric_pysdk) (5.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.11/dist-packages (from gevent<23.0.0,>=22.10.2->openfabric_pysdk) (7.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from gevent<23.0.0,>=22.10.2->openfabric_pysdk) (75.2.0)\n",
            "Requirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gevent<23.0.0,>=22.10.2->openfabric_pysdk) (3.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from socketio-client<0.8.0,>=0.7.2->openfabric_pysdk) (1.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio>=5.12.0->Flask-SocketIO<6.0.0,>=5.3.6->openfabric_pysdk) (0.23.1)\n",
            "Requirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio>=5.12.0->Flask-SocketIO<6.0.0,>=5.3.6->openfabric_pysdk) (4.12.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio>=5.12.0->Flask-SocketIO<6.0.0,>=5.3.6->openfabric_pysdk) (1.1.0)\n",
            "Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->Flask-SocketIO<6.0.0,>=5.3.6->openfabric_pysdk) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DzVgnK5GtvCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "j3j0RfhFnnLT",
        "outputId": "4734b0bb-6dee-477c-bc86-680988401875",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'marshmallow.base'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ab4bda128c1c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenfabric_pysdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenfabricExecutionRateLimiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenfabric_pysdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigClass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenfabric_pysdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenFabricStub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openfabric_pysdk/context/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessageType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbar_schema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBarSchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mray_schema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRaySchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmessage_schema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessageSchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openfabric_pysdk/context/bar_schema.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenfabric_pysdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSchema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openfabric_pysdk/fields/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmarshmallow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSchema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmarshmallow_jsonapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSchema\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mJApiSchema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjapifields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/marshmallow_jsonapi/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSchema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSchemaOpts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.24.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Schema\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SchemaOpts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/marshmallow_jsonapi/schema.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmarshmallow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseRelationship\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentMeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResourceMeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_RESOURCE_META_LOAD_FROM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DOCUMENT_META_LOAD_FROM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIncorrectTypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/marshmallow_jsonapi/fields.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Make core fields importable from marshmallow_jsonapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmarshmallow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmarshmallow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSchemaABC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmarshmallow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmissing_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'marshmallow.base'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import datetime\n",
        "import sqlite3\n",
        "import base64\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import torch\n",
        "from huggingface_hub import InferenceClient\n",
        "from openfabric_pysdk.context import OpenfabricExecutionRateLimiter\n",
        "from openfabric_pysdk.loader import ConfigClass\n",
        "from openfabric_pysdk.transport import OpenFabricStub\n",
        "\n",
        "# Check if GPU is available\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Create directories for storage\n",
        "os.makedirs(\"outputs/images\", exist_ok=True)\n",
        "os.makedirs(\"outputs/models\", exist_ok=True)\n",
        "os.makedirs(\"memory\", exist_ok=True)\n",
        "\n",
        "# Setup memory database\n",
        "conn = sqlite3.connect(\"memory/creative_memory.db\")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS creations (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp TEXT,\n",
        "    original_prompt TEXT,\n",
        "    enhanced_prompt TEXT,\n",
        "    image_path TEXT,\n",
        "    model_path TEXT,\n",
        "    tags TEXT\n",
        ")\n",
        "''')\n",
        "conn.commit()\n",
        "\n",
        "# HuggingFace LLM Configuration\n",
        "class HuggingFaceLLM:\n",
        "    def __init__(self):\n",
        "        print(\"Setting up HuggingFace Inference Client...\")\n",
        "        # Get HuggingFace API token from environment or prompt\n",
        "        self.api_token = os.environ.get(\"HF_TOKEN\")\n",
        "        if not self.api_token:\n",
        "            print(\"Please set your HF_TOKEN environment variable\")\n",
        "            self.api_token = input(\"Enter your HuggingFace API token: \")\n",
        "            os.environ[\"HF_TOKEN\"] = self.api_token\n",
        "\n",
        "        # Initialize the inference client\n",
        "        self.client = InferenceClient(token=self.api_token)\n",
        "\n",
        "        # Choose a model - default to Meta's Llama 3 8B Instruct model\n",
        "        self.model_name = \"meta-llama/Llama-3-8b-instruct\"\n",
        "        print(f\"HuggingFace Inference Client set up with model: {self.model_name}\")\n",
        "\n",
        "    def enhance_prompt(self, user_prompt):\n",
        "        \"\"\"Enhance the user prompt for better image generation using HuggingFace's hosted model\"\"\"\n",
        "        system_message = \"\"\"\n",
        "        You are a creative AI assistant specialized in enhancing prompts for image generation.\n",
        "        Your job is to take a simple prompt and expand it with vivid details, artistic style,\n",
        "        lighting, mood, and composition. Keep the core idea intact but make it visually rich.\n",
        "        \"\"\"\n",
        "\n",
        "        # Format prompt for llama-3 format\n",
        "        prompt = f\"\"\"<|system|>\n",
        "{system_message}\n",
        "<|user|>\n",
        "I want to generate an image of: {user_prompt}\n",
        "Please enhance this prompt to make it more detailed and visually appealing.\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Use the HuggingFace inference API\n",
        "            response = self.client.text_generation(\n",
        "                prompt,\n",
        "                model=self.model_name,\n",
        "                max_new_tokens=256,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "\n",
        "            enhanced_prompt = response.strip()\n",
        "\n",
        "            print(f\"Original prompt: {user_prompt}\")\n",
        "            print(f\"Enhanced prompt: {enhanced_prompt}\")\n",
        "\n",
        "            return enhanced_prompt\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with HuggingFace inference: {e}\")\n",
        "            # Fallback to original prompt if enhancement fails\n",
        "            print(\"Falling back to original prompt\")\n",
        "            return user_prompt\n",
        "\n",
        "# Openfabric SDK Configuration\n",
        "class OpenfabricConnector:\n",
        "    def __init__(self):\n",
        "        # You would need to set your Openfabric API key\n",
        "        self.api_key = os.environ.get(\"OPENFABRIC_API_KEY\")\n",
        "        if not self.api_key:\n",
        "            print(\"Please set your OPENFABRIC_API_KEY environment variable\")\n",
        "            self.api_key = input(\"Enter your Openfabric API key: \")\n",
        "            os.environ[\"OPENFABRIC_API_KEY\"] = self.api_key\n",
        "\n",
        "        # App IDs for the services\n",
        "        self.text2image_app_id = \"f0997a01-d6d3-a5fe-53d8-561300318557\"\n",
        "        self.image2model_app_id = \"69543f29-4d41-4afc-7f29-3d51591f11eb\"\n",
        "\n",
        "        # Initialize the stubs\n",
        "        self.text2image_stub = self._init_stub(self.text2image_app_id)\n",
        "        self.image2model_stub = self._init_stub(self.image2model_app_id)\n",
        "\n",
        "    def _init_stub(self, app_id):\n",
        "        \"\"\"Initialize and return an Openfabric stub for the specified app\"\"\"\n",
        "        config = ConfigClass()\n",
        "        config.manifest_url = f\"https://api.openfabric.network/v1/app/{app_id}/manifest\"\n",
        "        config.schema_url = f\"https://api.openfabric.network/v1/app/{app_id}/schema\"\n",
        "\n",
        "        print(f\"Initializing stub for app ID: {app_id}\")\n",
        "        try:\n",
        "            stub = OpenFabricStub(config)\n",
        "            print(f\"Stub initialized successfully for {app_id}\")\n",
        "            return stub\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing stub: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_image(self, prompt):\n",
        "        \"\"\"Generate an image from text using the Text-to-Image app\"\"\"\n",
        "        print(f\"Generating image from prompt: {prompt}\")\n",
        "\n",
        "        try:\n",
        "            # Create the request payload\n",
        "            request = {\n",
        "                \"prompt\": prompt,\n",
        "                \"negative_prompt\": \"blurry, low quality, distorted, deformed\",\n",
        "                \"width\": 768,\n",
        "                \"height\": 768,\n",
        "                \"num_inference_steps\": 50,\n",
        "                \"guidance_scale\": 7.5\n",
        "            }\n",
        "\n",
        "            # Execute the request with rate limiting\n",
        "            with OpenfabricExecutionRateLimiter():\n",
        "                response = self.text2image_stub.execute(request)\n",
        "\n",
        "            if not response or \"image\" not in response:\n",
        "                print(\"Failed to generate image: No valid response\")\n",
        "                return None\n",
        "\n",
        "            # Decode the base64 image\n",
        "            image_data = base64.b64decode(response[\"image\"])\n",
        "            image = Image.open(BytesIO(image_data))\n",
        "\n",
        "            # Save the image\n",
        "            timestamp = int(time.time())\n",
        "            image_path = f\"outputs/images/generated_{timestamp}.png\"\n",
        "            image.save(image_path)\n",
        "            print(f\"Image saved to {image_path}\")\n",
        "\n",
        "            return {\n",
        "                \"image\": image,\n",
        "                \"path\": image_path\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating image: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_3d_model(self, image_data):\n",
        "        \"\"\"Generate a 3D model from an image using the Image-to-3D app\"\"\"\n",
        "        print(\"Converting image to 3D model...\")\n",
        "\n",
        "        try:\n",
        "            # Prepare the image for the request\n",
        "            buffered = BytesIO()\n",
        "            image_data[\"image\"].save(buffered, format=\"PNG\")\n",
        "            image_base64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "            # Create the request payload\n",
        "            request = {\n",
        "                \"image\": image_base64\n",
        "            }\n",
        "\n",
        "            # Execute the request with rate limiting\n",
        "            with OpenfabricExecutionRateLimiter():\n",
        "                response = self.image2model_stub.execute(request)\n",
        "\n",
        "            if not response or \"model\" not in response:\n",
        "                print(\"Failed to generate 3D model: No valid response\")\n",
        "                return None\n",
        "\n",
        "            # Decode and save the 3D model\n",
        "            timestamp = int(time.time())\n",
        "            model_data = base64.b64decode(response[\"model\"])\n",
        "            model_path = f\"outputs/models/model_{timestamp}.glb\"\n",
        "\n",
        "            with open(model_path, \"wb\") as f:\n",
        "                f.write(model_data)\n",
        "\n",
        "            print(f\"3D model saved to {model_path}\")\n",
        "\n",
        "            return {\n",
        "                \"model_path\": model_path\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating 3D model: {e}\")\n",
        "            return None\n",
        "\n",
        "class MemoryManager:\n",
        "    def __init__(self, db_path=\"memory/creative_memory.db\"):\n",
        "        self.conn = sqlite3.connect(db_path)\n",
        "        self.cursor = self.conn.cursor()\n",
        "\n",
        "    def save_creation(self, original_prompt, enhanced_prompt, image_path, model_path, tags=None):\n",
        "        \"\"\"Save a creation to the memory database\"\"\"\n",
        "        if tags is None:\n",
        "            tags = []\n",
        "\n",
        "        # Extract keywords from the prompt for automatic tagging\n",
        "        if not tags:\n",
        "            # Simple keyword extraction\n",
        "            keywords = [word for word in enhanced_prompt.lower().split()\n",
        "                     if len(word) > 3 and word not in [\"with\", \"and\", \"the\", \"that\", \"this\"]]\n",
        "            tags = keywords[:5]  # Take top 5 keywords\n",
        "\n",
        "        timestamp = datetime.datetime.now().isoformat()\n",
        "\n",
        "        self.cursor.execute(\n",
        "            \"INSERT INTO creations (timestamp, original_prompt, enhanced_prompt, image_path, model_path, tags) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "            (timestamp, original_prompt, enhanced_prompt, image_path, model_path, \",\".join(tags))\n",
        "        )\n",
        "        self.conn.commit()\n",
        "\n",
        "        return self.cursor.lastrowid\n",
        "\n",
        "    def search_creations(self, query=None, limit=5):\n",
        "        \"\"\"Search for creations in the memory database\"\"\"\n",
        "        if query:\n",
        "            # Search in prompts and tags\n",
        "            self.cursor.execute(\n",
        "                \"SELECT * FROM creations WHERE original_prompt LIKE ? OR enhanced_prompt LIKE ? OR tags LIKE ? ORDER BY timestamp DESC LIMIT ?\",\n",
        "                (f\"%{query}%\", f\"%{query}%\", f\"%{query}%\", limit)\n",
        "            )\n",
        "        else:\n",
        "            # Get recent creations\n",
        "            self.cursor.execute(\"SELECT * FROM creations ORDER BY timestamp DESC LIMIT ?\", (limit,))\n",
        "\n",
        "        return self.cursor.fetchall()\n",
        "\n",
        "    def get_creation_by_id(self, creation_id):\n",
        "        \"\"\"Get a specific creation by ID\"\"\"\n",
        "        self.cursor.execute(\"SELECT * FROM creations WHERE id = ?\", (creation_id,))\n",
        "        return self.cursor.fetchone()\n",
        "\n",
        "# Main creative pipeline\n",
        "class CreativePipeline:\n",
        "    def __init__(self):\n",
        "        self.llm = HuggingFaceLLM()  # Now using HuggingFace instead of local LLM\n",
        "        self.openfabric = OpenfabricConnector()\n",
        "        self.memory = MemoryManager()\n",
        "\n",
        "    def create_from_prompt(self, user_prompt, enhance=True):\n",
        "        \"\"\"Full pipeline: prompt → enhanced prompt → image → 3D model\"\"\"\n",
        "        # Step 1: Enhance the prompt with the LLM\n",
        "        if enhance:\n",
        "            enhanced_prompt = self.llm.enhance_prompt(user_prompt)\n",
        "        else:\n",
        "            enhanced_prompt = user_prompt\n",
        "\n",
        "        # Step 2: Generate image from enhanced prompt\n",
        "        image_data = self.openfabric.generate_image(enhanced_prompt)\n",
        "        if not image_data:\n",
        "            return {\"error\": \"Failed to generate image\"}\n",
        "\n",
        "        # Step 3: Generate 3D model from image\n",
        "        model_data = self.openfabric.generate_3d_model(image_data)\n",
        "        if not model_data:\n",
        "            return {\"error\": \"Failed to generate 3D model\"}\n",
        "\n",
        "        # Step 4: Save to memory\n",
        "        creation_id = self.memory.save_creation(\n",
        "            original_prompt=user_prompt,\n",
        "            enhanced_prompt=enhanced_prompt,\n",
        "            image_path=image_data[\"path\"],\n",
        "            model_path=model_data[\"model_path\"]\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"creation_id\": creation_id,\n",
        "            \"original_prompt\": user_prompt,\n",
        "            \"enhanced_prompt\": enhanced_prompt,\n",
        "            \"image_path\": image_data[\"path\"],\n",
        "            \"model_path\": model_data[\"model_path\"]\n",
        "        }\n",
        "\n",
        "    def search_memory(self, query=None, limit=5):\n",
        "        \"\"\"Search memories for previous creations\"\"\"\n",
        "        return self.memory.search_creations(query, limit)\n",
        "\n",
        "# Set up a simple Gradio UI\n",
        "import gradio as gr\n",
        "\n",
        "def create_gradio_interface(pipeline):\n",
        "    def generate(prompt):\n",
        "        result = pipeline.create_from_prompt(prompt)\n",
        "        if \"error\" in result:\n",
        "            return None, None, result[\"error\"]\n",
        "\n",
        "        # Display the image and provide a download link for the 3D model\n",
        "        image = Image.open(result[\"image_path\"])\n",
        "        model_path = result[\"model_path\"]\n",
        "\n",
        "        return image, model_path, f\"\"\"\n",
        "        **Original Prompt:** {result['original_prompt']}\n",
        "\n",
        "        **Enhanced Prompt:** {result['enhanced_prompt']}\n",
        "\n",
        "        **Creation ID:** {result['creation_id']}\n",
        "\n",
        "        The 3D model is available for download.\n",
        "        \"\"\"\n",
        "\n",
        "    def search(query):\n",
        "        results = pipeline.search_memory(query)\n",
        "        if not results:\n",
        "            return \"No creations found matching your query.\"\n",
        "\n",
        "        output = \"## Found Creations\\n\\n\"\n",
        "        for r in results:\n",
        "            creation_id, timestamp, original, enhanced, img_path, model_path, tags = r\n",
        "            timestamp_dt = datetime.datetime.fromisoformat(timestamp)\n",
        "            formatted_time = timestamp_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            output += f\"### ID: {creation_id} - {formatted_time}\\n\"\n",
        "            output += f\"**Original:** {original}\\n\"\n",
        "            output += f\"**Enhanced:** {enhanced}\\n\"\n",
        "            output += f\"**Tags:** {tags}\\n\"\n",
        "            output += f\"**Image:** {img_path}\\n\"\n",
        "            output += f\"**Model:** {model_path}\\n\\n\"\n",
        "\n",
        "        return output\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Creative Partner: Text → Image → 3D Pipeline\")\n",
        "\n",
        "        with gr.Tab(\"Create\"):\n",
        "            with gr.Row():\n",
        "                prompt_input = gr.Textbox(label=\"Enter your creative prompt\", lines=3, placeholder=\"A glowing dragon standing on a cliff at sunset\")\n",
        "                generate_btn = gr.Button(\"Generate\")\n",
        "\n",
        "            with gr.Row():\n",
        "                image_output = gr.Image(label=\"Generated Image\")\n",
        "                model_output = gr.File(label=\"3D Model (GLB format)\")\n",
        "\n",
        "            result_text = gr.Markdown()\n",
        "\n",
        "            generate_btn.click(\n",
        "                generate,\n",
        "                inputs=[prompt_input],\n",
        "                outputs=[image_output, model_output, result_text]\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Memory\"):\n",
        "            with gr.Row():\n",
        "                search_input = gr.Textbox(label=\"Search your creations\", placeholder=\"dragon, sunset, cyberpunk...\")\n",
        "                search_btn = gr.Button(\"Search\")\n",
        "\n",
        "            memory_results = gr.Markdown()\n",
        "\n",
        "            search_btn.click(\n",
        "                search,\n",
        "                inputs=[search_input],\n",
        "                outputs=[memory_results]\n",
        "            )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Add functionality to select different HuggingFace models\n",
        "def select_model(model_name):\n",
        "    global pipeline\n",
        "    pipeline.llm.model_name = model_name\n",
        "    return f\"Model changed to: {model_name}\"\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    print(\"Initializing Creative Pipeline...\")\n",
        "    pipeline = CreativePipeline()\n",
        "\n",
        "    # Example 1: Direct use of the pipeline\n",
        "    print(\"\\n=== Example: Generating a dragon on a cliff ===\")\n",
        "    result = pipeline.create_from_prompt(\"A glowing dragon standing on a cliff at sunset\")\n",
        "    print(f\"Creation result: {json.dumps(result, indent=2)}\")\n",
        "\n",
        "    # Launch Gradio interface\n",
        "    print(\"\\n=== Launching Gradio Interface ===\")\n",
        "    demo = create_gradio_interface(pipeline)\n",
        "\n",
        "    # Add model selection dropdown\n",
        "    with demo:\n",
        "        with gr.Tab(\"Settings\"):\n",
        "            models = [\n",
        "                \"meta-llama/Llama-3-8b-instruct\",\n",
        "                \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "                \"google/gemma-7b-it\",\n",
        "                \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
        "            ]\n",
        "            model_dropdown = gr.Dropdown(\n",
        "                choices=models,\n",
        "                value=\"meta-llama/Llama-3-8b-instruct\",\n",
        "                label=\"Select HuggingFace Model\"\n",
        "            )\n",
        "            model_output = gr.Markdown()\n",
        "            model_dropdown.change(select_model, inputs=[model_dropdown], outputs=[model_output])\n",
        "\n",
        "    demo.launch(share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set API keys from environment if available\n",
        "    if os.environ.get(\"OPENFABRIC_API_KEY\") is None:\n",
        "        os.environ[\"OPENFABRIC_API_KEY\"] = input(\"Enter your Openfabric API key: \")\n",
        "\n",
        "    if os.environ.get(\"HF_TOKEN\") is None:\n",
        "        os.environ[\"HF_TOKEN\"] = input(\"\")\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "id": "PhGhe119w9Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install"
      ],
      "metadata": {
        "id": "ZE_AbOYenvJ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}